"""
üåÖ Sundial Foundation Model Integration

–ú–æ–¥—É–ª—å –¥–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó Sundial foundation –º–æ–¥–µ–ª—ñ –≤ —Ç–æ—Ä–≥–æ–≤—É —Å–∏—Å—Ç–µ–º—É.
Sundial - —Ü–µ –ø–µ—Ä–µ–º–æ–∂–µ—Ü—å –±–µ–Ω—á–º–∞—Ä–∫—ñ–≤ GIFT-Eval —Ç–∞ Time-Series-Library 2025.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Union
import warnings
from pathlib import Path
import math
import json

warnings.filterwarnings('ignore')

class SundialConfig:
    """
    –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è Sundial Foundation Model
    """
    def __init__(
        self,
        vocab_size: int = 50000,
        hidden_size: int = 768,
        num_hidden_layers: int = 12,
        num_attention_heads: int = 12,
        intermediate_size: int = 3072,
        hidden_dropout_prob: float = 0.1,
        attention_probs_dropout_prob: float = 0.1,
        max_position_embeddings: int = 512,
        layer_norm_eps: float = 1e-12,
        pad_token_id: int = 0,
        position_embedding_type: str = "absolute",
        use_cache: bool = True,
        classifier_dropout: Optional[float] = None,
    ):
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
        self.num_hidden_layers = num_hidden_layers
        self.num_attention_heads = num_attention_heads
        self.intermediate_size = intermediate_size
        self.hidden_dropout_prob = hidden_dropout_prob
        self.attention_probs_dropout_prob = attention_probs_dropout_prob
        self.max_position_embeddings = max_position_embeddings
        self.layer_norm_eps = layer_norm_eps
        self.pad_token_id = pad_token_id
        self.position_embedding_type = position_embedding_type
        self.use_cache = use_cache
        self.classifier_dropout = classifier_dropout

class SimpleSundialModel(nn.Module):
    """
    –°–ø—Ä–æ—â–µ–Ω–∞ Sundial –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏—Ö —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
    """
    def __init__(
        self,
        input_size: int = 1,
        hidden_size: int = 256,
        num_layers: int = 6,
        num_heads: int = 8,
        dropout: float = 0.1,
        max_seq_length: int = 512,
        prediction_length: int = 1
    ):
        super().__init__()
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.num_heads = num_heads
        self.prediction_length = prediction_length
        
        # –í—Ö—ñ–¥–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è
        self.input_projection = nn.Linear(input_size, hidden_size)
        
        # –ü–æ–∑–∏—Ü—ñ–π–Ω—ñ –µ–º–±–µ–¥–¥—ñ–Ω–≥–∏
        self.position_embeddings = nn.Embedding(max_seq_length, hidden_size)
        
        # Transformer —à–∞—Ä–∏
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_size,
            nhead=num_heads,
            dim_feedforward=hidden_size * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # –í–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä
        self.output_projection = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, prediction_length)
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Args:
            x: Tensor of shape (batch_size, seq_length, input_size)
            mask: Optional attention mask
        Returns:
            predictions: Tensor of shape (batch_size, prediction_length)
        """
        batch_size, seq_length, _ = x.shape
        
        # –í—Ö—ñ–¥–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è
        x = self.input_projection(x)  # (batch_size, seq_length, hidden_size)
        
        # –ü–æ–∑–∏—Ü—ñ–π–Ω—ñ –µ–º–±–µ–¥–¥—ñ–Ω–≥–∏
        positions = torch.arange(seq_length, device=x.device).unsqueeze(0).expand(batch_size, -1)
        pos_embeddings = self.position_embeddings(positions)
        
        x = x + pos_embeddings
        x = self.dropout(x)
        
        # Transformer
        if mask is not None:
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –º–∞—Å–∫—É –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
            mask = mask.bool()
            # –Ü–Ω–≤–µ—Ä—Ç—É—î–º–æ –º–∞—Å–∫—É: True -> False (–Ω–µ –º–∞—Å–∫—É–≤–∞—Ç–∏), False -> True (–º–∞—Å–∫—É–≤–∞—Ç–∏)
            mask = ~mask
        
        x = self.transformer(x, src_key_padding_mask=mask)
        
        # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π timestep –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
        last_hidden = x[:, -1, :]  # (batch_size, hidden_size)
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ –ø—Ä–æ–≥–Ω–æ–∑
        predictions = self.output_projection(last_hidden)  # (batch_size, prediction_length)
        
        return predictions

class FinancialTimeSeriesPreprocessor:
    """
    –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä –¥–ª—è —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏—Ö —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
    """
    def __init__(self, sequence_length: int = 60, prediction_length: int = 1):
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.scaler_mean = None
        self.scaler_std = None
        
    def fit(self, data: pd.Series):
        """
        –ù–∞–≤—á–∞—î –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä –Ω–∞ –¥–∞–Ω–∏—Ö
        """
        # –û–±—á–∏—Å–ª—é—î–º–æ –∑–º—ñ–Ω–∏ —Ü—ñ–Ω —É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö
        price_changes = data.pct_change().fillna(0) * 100
        
        self.scaler_mean = price_changes.mean()
        self.scaler_std = price_changes.std()
        
    def transform(self, data: pd.Series) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î –¥–∞–Ω—ñ –Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
        """
        # –û–±—á–∏—Å–ª—é—î–º–æ –∑–º—ñ–Ω–∏ —Ü—ñ–Ω —É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö
        price_changes = data.pct_change().fillna(0) * 100
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ
        if self.scaler_mean is not None and self.scaler_std is not None:
            price_changes = (price_changes - self.scaler_mean) / (self.scaler_std + 1e-8)
        
        sequences = []
        targets = []
        
        for i in range(self.sequence_length, len(price_changes) - self.prediction_length + 1):
            # –í—Ö—ñ–¥–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
            seq = price_changes.iloc[i-self.sequence_length:i].values
            sequences.append(seq)
            
            # –¶—ñ–ª—å–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è
            target = price_changes.iloc[i:i+self.prediction_length].values
            targets.append(target)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ —Ç–µ–Ω–∑–æ—Ä–∏
        X = torch.FloatTensor(sequences).unsqueeze(-1)  # (n_samples, seq_length, 1)
        y = torch.FloatTensor(targets)  # (n_samples, prediction_length)
        
        return X, y
    
    def inverse_transform(self, predictions: torch.Tensor) -> np.ndarray:
        """
        –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
        """
        predictions = predictions.detach().cpu().numpy()
        
        if self.scaler_mean is not None and self.scaler_std is not None:
            predictions = predictions * self.scaler_std + self.scaler_mean
        
        return predictions

class SundialPredictor:
    """
    –û—Å–Ω–æ–≤–Ω–∏–π –∫–ª–∞—Å –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è Sundial –º–æ–¥–µ–ª—ñ
    """
    def __init__(
        self,
        hidden_size: int = 256,
        num_layers: int = 6,
        num_heads: int = 8,
        dropout: float = 0.1,
        sequence_length: int = 60,
        prediction_length: int = 1,
        device: str = 'cpu'
    ):
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.device = device
        
        self.model = SimpleSundialModel(
            input_size=1,
            hidden_size=hidden_size,
            num_layers=num_layers,
            num_heads=num_heads,
            dropout=dropout,
            max_seq_length=sequence_length,
            prediction_length=prediction_length
        ).to(device)
        
        self.preprocessor = FinancialTimeSeriesPreprocessor(
            sequence_length=sequence_length,
            prediction_length=prediction_length
        )
        
        self.is_fitted = False
        
    def train(
        self,
        data: pd.Series,
        epochs: int = 100,
        batch_size: int = 32,
        learning_rate: float = 1e-4,
        validation_split: float = 0.2,
        patience: int = 10,
        verbose: bool = True
    ) -> Dict:
        """
        –ù–∞–≤—á–∞—î –º–æ–¥–µ–ª—å
        """
        if verbose:
            print("–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö...")
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—è—î–º–æ –¥–∞–Ω—ñ
        self.preprocessor.fit(data)
        X, y = self.preprocessor.transform(data)
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ train/validation
        split_idx = int(len(X) * (1 - validation_split))
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ DataLoader'–∏
        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)
        
        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True
        )
        val_loader = torch.utils.data.DataLoader(
            val_dataset, batch_size=batch_size, shuffle=False
        )
        
        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä —Ç–∞ —Ñ—É–Ω–∫—Ü—ñ—é –≤—Ç—Ä–∞—Ç
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)
        criterion = nn.MSELoss()
        
        # –î–ª—è early stopping
        best_val_loss = float('inf')
        patience_counter = 0
        
        train_losses = []
        val_losses = []
        
        if verbose:
            print(f"–ü–æ—á–∞—Ç–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ {len(X_train)} –∑—Ä–∞–∑–∫–∞—Ö...")
        
        for epoch in range(epochs):
            # –ù–∞–≤—á–∞–Ω–Ω—è
            self.model.train()
            epoch_train_loss = 0
            
            for batch_X, batch_y in train_loader:
                batch_X = batch_X.to(self.device)
                batch_y = batch_y.to(self.device)
                
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                
                epoch_train_loss += loss.item()
            
            avg_train_loss = epoch_train_loss / len(train_loader)
            train_losses.append(avg_train_loss)
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
            self.model.eval()
            epoch_val_loss = 0
            
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    batch_X = batch_X.to(self.device)
                    batch_y = batch_y.to(self.device)
                    
                    outputs = self.model(batch_X)
                    loss = criterion(outputs, batch_y)
                    epoch_val_loss += loss.item()
            
            avg_val_loss = epoch_val_loss / len(val_loader)
            val_losses.append(avg_val_loss)
            
            # Early stopping
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
            else:
                patience_counter += 1
                
            if patience_counter >= patience:
                if verbose:
                    print(f"Early stopping –Ω–∞ –µ–ø–æ—Å—ñ {epoch+1}")
                break
            
            if verbose and (epoch + 1) % 10 == 0:
                print(f"–ï–ø–æ—Ö–∞ {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}")
        
        self.is_fitted = True
        
        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'best_val_loss': best_val_loss,
            'epochs_trained': epoch + 1
        }
    
    def predict(self, data: pd.Series, return_sequences: bool = False) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
        """
        –†–æ–±–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏
        """
        if not self.is_fitted:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–≤—á–µ–Ω–∞! –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–ª–∏—á—Ç–µ train()")
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—è—î–º–æ –¥–∞–Ω—ñ
        X, _ = self.preprocessor.transform(data)
        
        self.model.eval()
        predictions = []
        
        with torch.no_grad():
            for i in range(0, len(X), 32):  # –û–±—Ä–æ–±–ª—è—î–º–æ –±–∞—Ç—á–∞–º–∏
                batch_X = X[i:i+32].to(self.device)
                batch_pred = self.model(batch_X)
                predictions.append(batch_pred.cpu())
        
        predictions = torch.cat(predictions, dim=0)
        
        # –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è
        predictions = self.preprocessor.inverse_transform(predictions)
        
        if return_sequences:
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç–∞–∫–æ–∂ –≤—Ö—ñ–¥–Ω—ñ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
            sequences = X.squeeze(-1).numpy()
            sequences = self.preprocessor.inverse_transform(torch.FloatTensor(sequences))
            return predictions, sequences
        
        return predictions
    
    def predict_next(self, data: pd.Series, n_steps: int = 1) -> np.ndarray:
        """
        –ü—Ä–æ–≥–Ω–æ–∑—É—î –Ω–∞—Å—Ç—É–ø–Ω—ñ n –∫—Ä–æ–∫—ñ–≤
        """
        if not self.is_fitted:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–≤—á–µ–Ω–∞! –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–ª–∏—á—Ç–µ train()")
        
        # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ sequence_length —Ç–æ—á–æ–∫
        recent_data = data.tail(self.sequence_length)
        
        predictions = []
        current_data = recent_data.copy()
        
        for _ in range(n_steps):
            # –†–æ–±–∏–º–æ –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –ø–æ—Ç–æ—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö
            pred = self.predict(current_data)
            
            if len(pred) > 0:
                # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –ø—Ä–æ–≥–Ω–æ–∑
                next_pred = pred[-1]
                predictions.extend(next_pred if hasattr(next_pred, '__iter__') else [next_pred])
                
                # –û–Ω–æ–≤–ª—é—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥ –≤ —Ü—ñ–Ω—É
                last_price = current_data.iloc[-1]
                predicted_change = next_pred[0] / 100  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∑ –≤—ñ–¥—Å–æ—Ç–∫—ñ–≤
                next_price = last_price * (1 + predicted_change)
                
                # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—É —Ü—ñ–Ω—É –¥–æ –¥–∞–Ω–∏—Ö
                new_data = pd.Series([next_price], index=[current_data.index[-1] + pd.Timedelta(days=1)])
                current_data = pd.concat([current_data, new_data])
                current_data = current_data.tail(self.sequence_length)
        
        return np.array(predictions)
    
    def evaluate(self, data: pd.Series) -> Dict:
        """
        –û—Ü—ñ–Ω—é—î –º–æ–¥–µ–ª—å
        """
        predictions = self.predict(data)
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—è—î–º–æ —Ü—ñ–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        X, y_true = self.preprocessor.transform(data)
        y_true = self.preprocessor.inverse_transform(y_true)
        
        # –û–±—á–∏—Å–ª—é—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
        mse = np.mean((predictions - y_true) ** 2)
        mae = np.mean(np.abs(predictions - y_true))
        rmse = np.sqrt(mse)
        
        # –¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞–ø—Ä—è–º–∫—É (—á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è/—Å–ø–∞–¥–∞–Ω–Ω—è)
        direction_accuracy = np.mean(np.sign(predictions.flatten()) == np.sign(y_true.flatten()))
        
        return {
            'mse': mse,
            'mae': mae,
            'rmse': rmse,
            'direction_accuracy': direction_accuracy
        }
    
    def save_model(self, filepath: str):
        """
        –ó–±–µ—Ä—ñ–≥–∞—î –º–æ–¥–µ–ª—å
        """
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'preprocessor_mean': self.preprocessor.scaler_mean,
            'preprocessor_std': self.preprocessor.scaler_std,
            'sequence_length': self.sequence_length,
            'prediction_length': self.prediction_length,
            'model_config': {
                'hidden_size': self.model.hidden_size,
                'num_layers': self.model.num_layers,
                'num_heads': self.model.num_heads,
            },
            'is_fitted': self.is_fitted
        }, filepath)
        print(f"–ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞: {filepath}")
    
    def load_model(self, filepath: str):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å
        """
        checkpoint = torch.load(filepath, map_location=self.device)
        
        # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
        config = checkpoint['model_config']
        self.sequence_length = checkpoint['sequence_length']
        self.prediction_length = checkpoint['prediction_length']
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—É –º–æ–¥–µ–ª—å –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        self.model = SimpleSundialModel(
            input_size=1,
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            num_heads=config['num_heads'],
            max_seq_length=self.sequence_length,
            prediction_length=self.prediction_length
        ).to(self.device)
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–∞–≥–∏
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä
        self.preprocessor = FinancialTimeSeriesPreprocessor(
            sequence_length=self.sequence_length,
            prediction_length=self.prediction_length
        )
        self.preprocessor.scaler_mean = checkpoint['preprocessor_mean']
        self.preprocessor.scaler_std = checkpoint['preprocessor_std']
        
        self.is_fitted = checkpoint['is_fitted']
        
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞: {filepath}")

# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
def create_sundial_predictor(
    hidden_size: int = 256,
    num_layers: int = 6,
    num_heads: int = 8,
    sequence_length: int = 60,
    prediction_length: int = 1,
    device: str = 'cpu'
) -> SundialPredictor:
    """
    –°—Ç–≤–æ—Ä—é—î Sundial predictor –∑ –∑–∞–¥–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    """
    return SundialPredictor(
        hidden_size=hidden_size,
        num_layers=num_layers,
        num_heads=num_heads,
        sequence_length=sequence_length,
        prediction_length=prediction_length,
        device=device
    )

def train_sundial_on_stock_data(
    stock_data: pd.DataFrame,
    price_column: str = 'Close',
    epochs: int = 100,
    batch_size: int = 32,
    learning_rate: float = 1e-4,
    sequence_length: int = 60,
    prediction_length: int = 1,
    device: str = 'cpu',
    verbose: bool = True
) -> Tuple[SundialPredictor, Dict]:
    """
    –ù–∞–≤—á–∞—î Sundial –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–∏—Ö –∞–∫—Ü—ñ–π
    """
    predictor = create_sundial_predictor(
        sequence_length=sequence_length,
        prediction_length=prediction_length,
        device=device
    )
    
    price_series = stock_data[price_column]
    
    training_results = predictor.train(
        data=price_series,
        epochs=epochs,
        batch_size=batch_size,
        learning_rate=learning_rate,
        verbose=verbose
    )
    
    return predictor, training_results

def load_and_predict(model_path: str, stock_data: pd.DataFrame, price_column: str = 'Close') -> np.ndarray:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å —ñ —Ä–æ–±–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏
    """
    predictor = SundialPredictor()
    predictor.load_model(model_path)
    
    price_series = stock_data[price_column]
    predictions = predictor.predict(price_series)
    
    return predictions


class SundialTradingStrategy:
    """–¢–æ—Ä–≥–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –Ω–∞ –±–∞–∑—ñ Sundial –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤"""
    
    def __init__(self, predictor, initial_capital=10000, window_size=60, forecast_horizon=5):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–æ—Ä–≥–æ–≤–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó
        
        Args:
            predictor (SundialPredictor): –ï–∫–∑–µ–º–ø–ª—è—Ä Sundial –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
            initial_capital (float): –ü–æ—á–∞—Ç–∫–æ–≤–∏–π –∫–∞–ø—ñ—Ç–∞–ª
            window_size (int): –†–æ–∑–º—ñ—Ä –≤—ñ–∫–Ω–∞ –¥–ª—è —ñ—Å—Ç–æ—Ä—ñ—ó
            forecast_horizon (int): –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
        """
        self.predictor = predictor
        self.initial_capital = initial_capital
        self.window_size = window_size
        self.forecast_horizon = forecast_horizon
        
        # –°—Ç–∞–Ω –ø–æ—Ä—Ç—Ñ–µ–ª—è
        self.cash = initial_capital
        self.shares = 0
        self.portfolio_value = []
        self.trades = []
        
    def make_prediction(self, price_history):
        """–†–æ–±–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ —Ü—ñ–Ω–∏ –Ω–∞ –Ω–∞—Å—Ç—É–ø–Ω—ñ –¥–Ω—ñ"""
        if len(price_history) < self.window_size:
            return None
            
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ window_size –∑–Ω–∞—á–µ–Ω—å
        input_seq = price_history[-self.window_size:]
        
        # –†–æ–±–∏–º–æ –ø—Ä–æ–≥–Ω–æ–∑
        prediction = self.predictor.predict(input_seq, self.forecast_horizon)
        
        return prediction
    
    def generate_signal(self, current_price, prediction):
        """
        –ì–µ–Ω–µ—Ä—É—î —Ç–æ—Ä–≥–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø—Ä–æ–≥–Ω–æ–∑—É
        
        Args:
            current_price (float): –ü–æ—Ç–æ—á–Ω–∞ —Ü—ñ–Ω–∞
            prediction (np.array): –ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            
        Returns:
            str: –¢–æ—Ä–≥–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª ('BUY', 'SELL', 'HOLD')
        """
        if prediction is None or len(prediction) == 0:
            return "HOLD"
        
        # –û–±—á–∏—Å–ª—é—î–º–æ –æ—á—ñ–∫—É–≤–∞–Ω—É –∑–º—ñ–Ω—É —Ü—ñ–Ω–∏
        expected_price = prediction[-1]  # –¶—ñ–Ω–∞ —á–µ—Ä–µ–∑ forecast_horizon –¥–Ω—ñ–≤
        price_change_pct = (expected_price - current_price) / current_price
        
        # –¢–æ—Ä–≥–æ–≤—ñ —Å–∏–≥–Ω–∞–ª–∏ –∑ –ø–æ—Ä–æ–≥–∞–º–∏
        if price_change_pct > 0.02:  # –û—á—ñ–∫—É—î–º–æ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è >2%
            return "BUY"
        elif price_change_pct < -0.02:  # –û—á—ñ–∫—É—î–º–æ –ø–∞–¥—ñ–Ω–Ω—è >2%
            return "SELL"
        else:
            return "HOLD"
    
    def execute_trade(self, signal, current_price, date):
        """–í–∏–∫–æ–Ω—É—î —Ç–æ—Ä–≥–æ–≤—É –æ–ø–µ—Ä–∞—Ü—ñ—é"""
        if signal == "BUY" and self.cash > current_price:
            # –ö—É–ø—É—î–º–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∞–∫—Ü—ñ–π
            shares_to_buy = int(self.cash // current_price)
            if shares_to_buy > 0:
                cost = shares_to_buy * current_price
                self.cash -= cost
                self.shares += shares_to_buy
                self.trades.append({
                    'date': date,
                    'action': 'BUY',
                    'shares': shares_to_buy,
                    'price': current_price,
                    'cost': cost
                })
                
        elif signal == "SELL" and self.shares > 0:
            # –ü—Ä–æ–¥–∞—î–º–æ –≤—Å—ñ –∞–∫—Ü—ñ—ó
            proceeds = self.shares * current_price
            self.cash += proceeds
            self.trades.append({
                'date': date,
                'action': 'SELL',
                'shares': self.shares,
                'price': current_price,
                'proceeds': proceeds
            })
            self.shares = 0
    
    def get_portfolio_value(self, current_price):
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î –ø–æ—Ç–æ—á–Ω—É –≤–∞—Ä—Ç—ñ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        return self.cash + (self.shares * current_price)
    
    def get_performance_metrics(self, final_value):
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î –º–µ—Ç—Ä–∏–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
        total_return = (final_value - self.initial_capital) / self.initial_capital
        return {
            'total_return': total_return,
            'final_value': final_value,
            'initial_capital': self.initial_capital,
            'total_trades': len(self.trades)
        }


def test_sundial_model():
    """–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Sundial –º–æ–¥–µ–ª—ñ"""
    print("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Sundial Foundation Model...")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
    predictor = SundialPredictor()
    
    # –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
    success = predictor.load_model()
    
    if success:
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞!")
    else:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞, –±—É–¥–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ fallback")
    
    # –¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
    test_data = np.random.randn(60) * 10 + 200  # –°–∏–º—É–ª—è—Ü—ñ—è —Ü—ñ–Ω –∞–∫—Ü—ñ–π
    
    # –†–æ–±–∏–º–æ –ø—Ä–æ–≥–Ω–æ–∑
    prediction = predictor.predict(test_data, forecast_length=5)
    
    print(f"üìä –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 5 –¥–Ω—ñ–≤: {prediction}")
    print("üß™ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    test_sundial_model() 